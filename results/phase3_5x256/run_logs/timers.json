{
    "name": "root",
    "gauges": {
        "DroneDefender.Policy.Entropy.mean": {
            "value": 0.5987114906311035,
            "min": 0.5906270742416382,
            "max": 0.5987114906311035,
            "count": 10
        },
        "DroneDefender.Policy.Entropy.sum": {
            "value": 5963.76513671875,
            "min": 1216.4329833984375,
            "max": 6035.177734375,
            "count": 10
        },
        "DroneDefender.Environment.EpisodeLength.mean": {
            "value": 46.484375,
            "min": 13.53125,
            "max": 50.213973799126634,
            "count": 10
        },
        "DroneDefender.Environment.EpisodeLength.sum": {
            "value": 8925.0,
            "min": 433.0,
            "max": 11499.0,
            "count": 10
        },
        "DroneDefender.Step.mean": {
            "value": 31629950.0,
            "min": 31539950.0,
            "max": 31629950.0,
            "count": 10
        },
        "DroneDefender.Step.sum": {
            "value": 31629950.0,
            "min": 31539950.0,
            "max": 31629950.0,
            "count": 10
        },
        "DroneDefender.Policy.ExtrinsicValueEstimate.mean": {
            "value": -1477.808349609375,
            "min": -1643.8800048828125,
            "max": -1269.7183837890625,
            "count": 10
        },
        "DroneDefender.Policy.ExtrinsicValueEstimate.sum": {
            "value": -441864.6875,
            "min": -544094.0,
            "max": -87125.640625,
            "count": 10
        },
        "DroneDefender.Environment.CumulativeReward.mean": {
            "value": -2546.0106579462686,
            "min": -2767.936856865362,
            "max": -1315.8798828125,
            "count": 10
        },
        "DroneDefender.Environment.CumulativeReward.sum": {
            "value": -488834.0463256836,
            "min": -633857.540222168,
            "max": -42108.15625,
            "count": 10
        },
        "DroneDefender.Policy.ExtrinsicReward.mean": {
            "value": -2546.0106579462686,
            "min": -2767.936856865362,
            "max": -1315.8798828125,
            "count": 10
        },
        "DroneDefender.Policy.ExtrinsicReward.sum": {
            "value": -488834.0463256836,
            "min": -633857.540222168,
            "max": -42108.15625,
            "count": 10
        },
        "DroneDefender.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "DroneDefender.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "DroneAttacker.Policy.Entropy.mean": {
            "value": 0.5339348912239075,
            "min": 0.5339348912239075,
            "max": 0.5384521484375,
            "count": 9
        },
        "DroneAttacker.Policy.Entropy.sum": {
            "value": 5334.009765625,
            "min": 2301.8828125,
            "max": 5421.2109375,
            "count": 9
        },
        "DroneAttacker.Environment.EpisodeLength.mean": {
            "value": 243.53488372093022,
            "min": 100.6875,
            "max": 350.4,
            "count": 9
        },
        "DroneAttacker.Environment.EpisodeLength.sum": {
            "value": 10472.0,
            "min": 3222.0,
            "max": 11943.0,
            "count": 9
        },
        "DroneAttacker.Step.mean": {
            "value": 8939962.0,
            "min": 8859983.0,
            "max": 8939962.0,
            "count": 9
        },
        "DroneAttacker.Step.sum": {
            "value": 8939962.0,
            "min": 8859983.0,
            "max": 8939962.0,
            "count": 9
        },
        "DroneAttacker.Policy.ExtrinsicValueEstimate.mean": {
            "value": 305.84161376953125,
            "min": 132.4376983642578,
            "max": 340.8023681640625,
            "count": 9
        },
        "DroneAttacker.Policy.ExtrinsicValueEstimate.sum": {
            "value": 54745.6484375,
            "min": 22779.28515625,
            "max": 63389.2421875,
            "count": 9
        },
        "DroneAttacker.Environment.CumulativeReward.mean": {
            "value": 436.0697677301806,
            "min": 199.53448359719638,
            "max": 699.3500003814697,
            "count": 9
        },
        "DroneAttacker.Environment.CumulativeReward.sum": {
            "value": 18751.000012397766,
            "min": 5786.500024318695,
            "max": 46338.59991455078,
            "count": 9
        },
        "DroneAttacker.Policy.ExtrinsicReward.mean": {
            "value": 436.0697677301806,
            "min": 199.53448359719638,
            "max": 699.3500003814697,
            "count": 9
        },
        "DroneAttacker.Policy.ExtrinsicReward.sum": {
            "value": 18751.000012397766,
            "min": 5786.500024318695,
            "max": 46338.59991455078,
            "count": 9
        },
        "DroneAttacker.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 9
        },
        "DroneAttacker.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 9
        },
        "DroneDefender.Losses.PolicyLoss.mean": {
            "value": 0.037767920984576146,
            "min": 0.027604337657491367,
            "max": 0.12803247943520546,
            "count": 8
        },
        "DroneDefender.Losses.PolicyLoss.sum": {
            "value": 0.037767920984576146,
            "min": 0.027604337657491367,
            "max": 0.12803247943520546,
            "count": 8
        },
        "DroneDefender.Losses.ValueLoss.mean": {
            "value": 75999.396875,
            "min": 60152.46770833333,
            "max": 91628.63216145833,
            "count": 8
        },
        "DroneDefender.Losses.ValueLoss.sum": {
            "value": 75999.396875,
            "min": 60152.46770833333,
            "max": 91628.63216145833,
            "count": 8
        },
        "DroneDefender.Policy.LearningRate.mean": {
            "value": 0.0002905138813620405,
            "min": 0.0002905138813620405,
            "max": 0.0002905354849548394,
            "count": 8
        },
        "DroneDefender.Policy.LearningRate.sum": {
            "value": 0.0002905138813620405,
            "min": 0.0002905138813620405,
            "max": 0.0002905354849548394,
            "count": 8
        },
        "DroneDefender.Policy.Epsilon.mean": {
            "value": 0.19683795939999996,
            "min": 0.19683795939999996,
            "max": 0.19684516059999996,
            "count": 8
        },
        "DroneDefender.Policy.Epsilon.sum": {
            "value": 0.19683795939999996,
            "min": 0.19683795939999996,
            "max": 0.19684516059999996,
            "count": 8
        },
        "DroneDefender.Policy.Beta.mean": {
            "value": 0.00048450600106000007,
            "min": 0.00048450600106000007,
            "max": 0.0004845412869399999,
            "count": 8
        },
        "DroneDefender.Policy.Beta.sum": {
            "value": 0.00048450600106000007,
            "min": 0.00048450600106000007,
            "max": 0.0004845412869399999,
            "count": 8
        },
        "DroneAttacker.Losses.PolicyLoss.mean": {
            "value": 0.02131106414211293,
            "min": 0.019901066832244397,
            "max": 0.032431028705711164,
            "count": 8
        },
        "DroneAttacker.Losses.PolicyLoss.sum": {
            "value": 0.02131106414211293,
            "min": 0.019901066832244397,
            "max": 0.032431028705711164,
            "count": 8
        },
        "DroneAttacker.Losses.ValueLoss.mean": {
            "value": 17366.8333984375,
            "min": 11209.551155598958,
            "max": 33974.60735677083,
            "count": 8
        },
        "DroneAttacker.Losses.ValueLoss.sum": {
            "value": 17366.8333984375,
            "min": 11209.551155598958,
            "max": 33974.60735677083,
            "count": 8
        },
        "DroneAttacker.Policy.LearningRate.mean": {
            "value": 0.00029731853879382057,
            "min": 0.00029731853879382057,
            "max": 0.00029734013638662145,
            "count": 8
        },
        "DroneAttacker.Policy.LearningRate.sum": {
            "value": 0.00029731853879382057,
            "min": 0.00029731853879382057,
            "max": 0.00029734013638662145,
            "count": 8
        },
        "DroneAttacker.Policy.Epsilon.mean": {
            "value": 0.19910617930000007,
            "min": 0.19910617930000007,
            "max": 0.1991133785,
            "count": 8
        },
        "DroneAttacker.Policy.Epsilon.sum": {
            "value": 0.19910617930000007,
            "min": 0.19910617930000007,
            "max": 0.1991133785,
            "count": 8
        },
        "DroneAttacker.Policy.Beta.mean": {
            "value": 0.0004956202785699998,
            "min": 0.0004956202785699998,
            "max": 0.0004956555546500001,
            "count": 8
        },
        "DroneAttacker.Policy.Beta.sum": {
            "value": 0.0004956202785699998,
            "min": 0.0004956202785699998,
            "max": 0.0004956555546500001,
            "count": 8
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1748102958",
        "python_version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\User\\drone-hunting-by-a-drone-swarm\\venv\\Scripts\\mlagents-learn config/phase3_config.yaml --run-id=phase3_5x256 --resume",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.7.0+cu118",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1748103195"
    },
    "total": 236.75902909999786,
    "count": 1,
    "self": 0.007496999995055376,
    "children": {
        "run_training.setup": {
            "total": 0.08685030000197003,
            "count": 1,
            "self": 0.08685030000197003
        },
        "TrainerController.start_learning": {
            "total": 236.66468180000084,
            "count": 1,
            "self": 0.23557779971088166,
            "children": {
                "TrainerController._reset_env": {
                    "total": 8.93413800000053,
                    "count": 1,
                    "self": 8.93413800000053
                },
                "TrainerController.advance": {
                    "total": 227.1337072002898,
                    "count": 11622,
                    "self": 0.2578623005283589,
                    "children": {
                        "env_step": {
                            "total": 166.3376507998073,
                            "count": 11622,
                            "self": 102.91336929939644,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 63.28634390031948,
                                    "count": 11622,
                                    "self": 1.1867640003220004,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 62.09957989999748,
                                            "count": 19813,
                                            "self": 62.09957989999748
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.13793760009139078,
                                    "count": 11621,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 224.9359805998247,
                                            "count": 11621,
                                            "is_parallel": true,
                                            "self": 141.68044909969103,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0016609000012977049,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.0003623000011430122,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0012986000001546927,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0012986000001546927
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 83.25387060013236,
                                                    "count": 11621,
                                                    "is_parallel": true,
                                                    "self": 1.6043509001247003,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 2.5058037001872435,
                                                            "count": 11621,
                                                            "is_parallel": true,
                                                            "self": 2.5058037001872435
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 75.1868674999132,
                                                            "count": 11621,
                                                            "is_parallel": true,
                                                            "self": 75.1868674999132
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 3.9568484999072098,
                                                            "count": 23242,
                                                            "is_parallel": true,
                                                            "self": 1.5897919998060388,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 2.367056500101171,
                                                                    "count": 46484,
                                                                    "is_parallel": true,
                                                                    "self": 2.367056500101171
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 60.538194099954126,
                            "count": 23242,
                            "self": 0.4537188998547208,
                            "children": {
                                "process_trajectory": {
                                    "total": 32.116257800102176,
                                    "count": 23242,
                                    "self": 32.116257800102176
                                },
                                "_update_policy": {
                                    "total": 27.96821739999723,
                                    "count": 17,
                                    "self": 15.85488299998542,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 12.113334400011809,
                                            "count": 510,
                                            "self": 12.113334400011809
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 4.300000000512227e-06,
                    "count": 1,
                    "self": 4.300000000512227e-06
                },
                "TrainerController._save_models": {
                    "total": 0.36125449999963166,
                    "count": 1,
                    "self": 0.04858379999859608,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.3126707000010356,
                            "count": 2,
                            "self": 0.3126707000010356
                        }
                    }
                }
            }
        }
    }
}