{
    "name": "root",
    "gauges": {
        "DroneFlight.Policy.Entropy.mean": {
            "value": 2.374046564102173,
            "min": 2.346029281616211,
            "max": 2.409881353378296,
            "count": 289
        },
        "DroneFlight.Policy.Entropy.sum": {
            "value": 24661.595703125,
            "min": 15915.91796875,
            "max": 27083.15234375,
            "count": 289
        },
        "DroneFlight.Environment.EpisodeLength.mean": {
            "value": 117.52873563218391,
            "min": 94.66666666666667,
            "max": 147.11688311688312,
            "count": 289
        },
        "DroneFlight.Environment.EpisodeLength.sum": {
            "value": 10225.0,
            "min": 3408.0,
            "max": 12537.0,
            "count": 289
        },
        "DroneFlight.Step.mean": {
            "value": 84059957.0,
            "min": 81179954.0,
            "max": 84059957.0,
            "count": 289
        },
        "DroneFlight.Step.sum": {
            "value": 84059957.0,
            "min": 81179954.0,
            "max": 84059957.0,
            "count": 289
        },
        "DroneFlight.Policy.ExtrinsicValueEstimate.mean": {
            "value": 37.36412811279297,
            "min": 17.823375701904297,
            "max": 40.321022033691406,
            "count": 289
        },
        "DroneFlight.Policy.ExtrinsicValueEstimate.sum": {
            "value": 7547.5537109375,
            "min": 2988.8095703125,
            "max": 8346.451171875,
            "count": 289
        },
        "DroneFlight.Environment.CumulativeReward.mean": {
            "value": 12.886375909564139,
            "min": -37.67706750028877,
            "max": 21.787678718566895,
            "count": 289
        },
        "DroneFlight.Environment.CumulativeReward.sum": {
            "value": 1121.11470413208,
            "min": -3503.9672775268555,
            "max": 1830.1650123596191,
            "count": 289
        },
        "DroneFlight.Policy.ExtrinsicReward.mean": {
            "value": 12.886375909564139,
            "min": -37.67706750028877,
            "max": 21.787678718566895,
            "count": 289
        },
        "DroneFlight.Policy.ExtrinsicReward.sum": {
            "value": 1121.11470413208,
            "min": -3503.9672775268555,
            "max": 1830.1650123596191,
            "count": 289
        },
        "DroneFlight.Losses.PolicyLoss.mean": {
            "value": 0.030563827099589012,
            "min": 0.024617934725635372,
            "max": 0.07154486825068791,
            "count": 289
        },
        "DroneFlight.Losses.PolicyLoss.sum": {
            "value": 0.061127654199178025,
            "min": 0.031903163607542716,
            "max": 0.21463460475206375,
            "count": 289
        },
        "DroneFlight.Losses.ValueLoss.mean": {
            "value": 71.5293638308843,
            "min": 18.780482749144234,
            "max": 237.89058113098145,
            "count": 289
        },
        "DroneFlight.Losses.ValueLoss.sum": {
            "value": 143.0587276617686,
            "min": 37.56096549828847,
            "max": 551.0981012980143,
            "count": 289
        },
        "DroneFlight.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 289
        },
        "DroneFlight.Policy.LearningRate.sum": {
            "value": 0.0006,
            "min": 0.0003,
            "max": 0.0009,
            "count": 289
        },
        "DroneFlight.Policy.Epsilon.mean": {
            "value": 0.20000000000000004,
            "min": 0.20000000000000004,
            "max": 0.20000000000000007,
            "count": 289
        },
        "DroneFlight.Policy.Epsilon.sum": {
            "value": 0.4000000000000001,
            "min": 0.20000000000000004,
            "max": 0.6000000000000001,
            "count": 289
        },
        "DroneFlight.Policy.Beta.mean": {
            "value": 0.0005,
            "min": 0.0005,
            "max": 0.0005,
            "count": 289
        },
        "DroneFlight.Policy.Beta.sum": {
            "value": 0.001,
            "min": 0.0005,
            "max": 0.0015,
            "count": 289
        },
        "DroneFlight.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 289
        },
        "DroneFlight.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 289
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1748867415",
        "python_version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\User\\drone-hunting-by-a-drone-swarm\\venv\\Scripts\\mlagents-learn config/phase2_config.yaml --run-id=DroneFlight_20mRay --resume",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.7.0+cu118",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1748869618"
    },
    "total": 2203.640949099994,
    "count": 1,
    "self": 0.005715300008887425,
    "children": {
        "run_training.setup": {
            "total": 0.10264849998930003,
            "count": 1,
            "self": 0.10264849998930003
        },
        "TrainerController.start_learning": {
            "total": 2203.532585299996,
            "count": 1,
            "self": 1.7060860010096803,
            "children": {
                "TrainerController._reset_env": {
                    "total": 10.481772400002228,
                    "count": 1,
                    "self": 10.481772400002228
                },
                "TrainerController.advance": {
                    "total": 2191.2027185989864,
                    "count": 77244,
                    "self": 1.4200681981310481,
                    "children": {
                        "env_step": {
                            "total": 1210.978231500223,
                            "count": 77244,
                            "self": 1016.33023960008,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 193.72631590058154,
                                    "count": 77245,
                                    "self": 4.793460099346703,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 188.93285580123484,
                                            "count": 59041,
                                            "self": 188.93285580123484
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.9216759995615575,
                                    "count": 77243,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 2102.1457823004603,
                                            "count": 77243,
                                            "is_parallel": true,
                                            "self": 1311.0918773988378,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0016825000056996942,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.000390600020182319,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0012918999855173752,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0012918999855173752
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 791.0522224016167,
                                                    "count": 77243,
                                                    "is_parallel": true,
                                                    "self": 17.88536010500684,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 31.11194309964776,
                                                            "count": 77243,
                                                            "is_parallel": true,
                                                            "self": 31.11194309964776
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 703.4565495975548,
                                                            "count": 77243,
                                                            "is_parallel": true,
                                                            "self": 703.4565495975548
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 38.598369599407306,
                                                            "count": 77243,
                                                            "is_parallel": true,
                                                            "self": 8.463090194214601,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 30.135279405192705,
                                                                    "count": 154486,
                                                                    "is_parallel": true,
                                                                    "self": 30.135279405192705
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 978.8044189006323,
                            "count": 77243,
                            "self": 3.325792603631271,
                            "children": {
                                "process_trajectory": {
                                    "total": 385.96578599677014,
                                    "count": 77243,
                                    "self": 385.28963779676997,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.6761482000001706,
                                            "count": 6,
                                            "self": 0.6761482000001706
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 589.5128403002309,
                                    "count": 697,
                                    "self": 255.82228669979668,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 333.6905536004342,
                                            "count": 16734,
                                            "self": 333.6905536004342
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.14200829999754205,
                    "count": 1,
                    "self": 0.011324799997964874,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.13068349999957718,
                            "count": 1,
                            "self": 0.13068349999957718
                        }
                    }
                }
            }
        }
    }
}